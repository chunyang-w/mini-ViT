# Mini ViT

This is a minimal ViT implementation from scratch for demonstrational/educational purposes.

<img width="735" alt="image" src="https://github.com/user-attachments/assets/35fb427d-6c64-4e5b-9820-5d70de1160f9">

(Figure From [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929) by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby)


Implementation:

+ [Attention Block](https://github.com/chunyang-w/mini-ViT/blob/1fa33a7705bc7cc759d8a7be130b058d352dc9b0/vit.py#L9-L38)
+ [Multi-head Attention Block](https://github.com/chunyang-w/mini-ViT/blob/1fa33a7705bc7cc759d8a7be130b058d352dc9b0/vit.py#L41-L119)
+ [Simple Transformer](https://github.com/chunyang-w/mini-ViT/blob/1fa33a7705bc7cc759d8a7be130b058d352dc9b0/vit.py#L122-L186)
+ [ViT](https://github.com/chunyang-w/mini-ViT/blob/1fa33a7705bc7cc759d8a7be130b058d352dc9b0/vit.py#L189-L250)

[Tested on MNIST dataset](https://github.com/chunyang-w/mini-ViT/blob/main/demo.ipynb):

<img width="735" alt="image" src="https://github.com/user-attachments/assets/8c9ffc74-e9be-44cc-bdbc-c4d1b28f0ef2">
![image](https://github.com/user-attachments/assets/8c9ffc74-e9be-44cc-bdbc-c4d1b28f0ef2)
